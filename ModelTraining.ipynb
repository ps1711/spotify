{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96c2abf-1689-4d8c-81bd-db34bae41a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"spotify_millsongdata.csv\")\n",
    "df_sample = df.sample(frac = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3cd3467-7836-40eb-b8ae-f0713e9c38fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15646</th>\n",
       "      <td>Paul Simon</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>/p/paul+simon/youre+the+one_10202261.html</td>\n",
       "      <td>May twelve angels guard you  \\r\\nWhile you sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>Fifth Harmony</td>\n",
       "      <td>Top Down</td>\n",
       "      <td>/f/fifth+harmony/top+down_21094403.html</td>\n",
       "      <td>[Hook]  \\r\\nBlaze it up and we'll be cruisin' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>You Know How We Do It</td>\n",
       "      <td>/i/ice+cube/you+know+how+we+do+it_10143549.html</td>\n",
       "      <td>Yeah, yeah!  \\r\\nFool you know how we do it  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>Chaka Khan</td>\n",
       "      <td>Half Moon</td>\n",
       "      <td>/c/chaka+khan/half+moon_20028934.html</td>\n",
       "      <td>Half Moon, Nighttime sky  \\r\\nSilver stone, He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47330</th>\n",
       "      <td>Passenger</td>\n",
       "      <td>Holes</td>\n",
       "      <td>/p/passenger/holes_21072188.html</td>\n",
       "      <td>I know a man with nothing in his hands, nothin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                   song  \\\n",
       "15646     Paul Simon         You're The One   \n",
       "6005   Fifth Harmony               Top Down   \n",
       "8132        Ice Cube  You Know How We Do It   \n",
       "2379      Chaka Khan              Half Moon   \n",
       "47330      Passenger                  Holes   \n",
       "\n",
       "                                                  link  \\\n",
       "15646        /p/paul+simon/youre+the+one_10202261.html   \n",
       "6005           /f/fifth+harmony/top+down_21094403.html   \n",
       "8132   /i/ice+cube/you+know+how+we+do+it_10143549.html   \n",
       "2379             /c/chaka+khan/half+moon_20028934.html   \n",
       "47330                 /p/passenger/holes_21072188.html   \n",
       "\n",
       "                                                    text  \n",
       "15646  May twelve angels guard you  \\r\\nWhile you sle...  \n",
       "6005   [Hook]  \\r\\nBlaze it up and we'll be cruisin' ...  \n",
       "8132   Yeah, yeah!  \\r\\nFool you know how we do it  \\...  \n",
       "2379   Half Moon, Nighttime sky  \\r\\nSilver stone, He...  \n",
       "47330  I know a man with nothing in his hands, nothin...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c34be426-1dfa-4e64-97b1-812ecebe88f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57645</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Good Old Days</td>\n",
       "      <td>/z/ziggy+marley/good+old+days_10198588.html</td>\n",
       "      <td>Irie days come on play  \\r\\nLet the angels fly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57646</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Hand To Mouth</td>\n",
       "      <td>/z/ziggy+marley/hand+to+mouth_20531167.html</td>\n",
       "      <td>Power to the workers  \\r\\nMore power  \\r\\nPowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57647</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Come With Me</td>\n",
       "      <td>/z/zwan/come+with+me_20148981.html</td>\n",
       "      <td>all you need  \\r\\nis something i'll believe  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57648</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Desire</td>\n",
       "      <td>/z/zwan/desire_20148986.html</td>\n",
       "      <td>northern star  \\r\\nam i frightened  \\r\\nwhere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57649</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Heartsong</td>\n",
       "      <td>/z/zwan/heartsong_20148991.html</td>\n",
       "      <td>come in  \\r\\nmake yourself at home  \\r\\ni'm a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist           song  \\\n",
       "57645  Ziggy Marley  Good Old Days   \n",
       "57646  Ziggy Marley  Hand To Mouth   \n",
       "57647          Zwan   Come With Me   \n",
       "57648          Zwan         Desire   \n",
       "57649          Zwan      Heartsong   \n",
       "\n",
       "                                              link  \\\n",
       "57645  /z/ziggy+marley/good+old+days_10198588.html   \n",
       "57646  /z/ziggy+marley/hand+to+mouth_20531167.html   \n",
       "57647           /z/zwan/come+with+me_20148981.html   \n",
       "57648                 /z/zwan/desire_20148986.html   \n",
       "57649              /z/zwan/heartsong_20148991.html   \n",
       "\n",
       "                                                    text  \n",
       "57645  Irie days come on play  \\r\\nLet the angels fly...  \n",
       "57646  Power to the workers  \\r\\nMore power  \\r\\nPowe...  \n",
       "57647  all you need  \\r\\nis something i'll believe  \\...  \n",
       "57648  northern star  \\r\\nam i frightened  \\r\\nwhere ...  \n",
       "57649  come in  \\r\\nmake yourself at home  \\r\\ni'm a ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96095e67-4dac-4b41-b0d5-241a1db95b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5765, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f4cdbe-393c-400d-a668-a60360a648b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist    0\n",
       "song      0\n",
       "link      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc334125-0695-489a-a4a8-ed17b843c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.drop('link',axis = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90f390a-3aca-466d-bb4b-d795ba8ac948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paul Simon</td>\n",
       "      <td>You're The One</td>\n",
       "      <td>May twelve angels guard you  \\r\\nWhile you sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fifth Harmony</td>\n",
       "      <td>Top Down</td>\n",
       "      <td>[Hook]  \\r\\nBlaze it up and we'll be cruisin' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ice Cube</td>\n",
       "      <td>You Know How We Do It</td>\n",
       "      <td>Yeah, yeah!  \\r\\nFool you know how we do it  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaka Khan</td>\n",
       "      <td>Half Moon</td>\n",
       "      <td>Half Moon, Nighttime sky  \\r\\nSilver stone, He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Passenger</td>\n",
       "      <td>Holes</td>\n",
       "      <td>I know a man with nothing in his hands, nothin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                   song  \\\n",
       "0     Paul Simon         You're The One   \n",
       "1  Fifth Harmony               Top Down   \n",
       "2       Ice Cube  You Know How We Do It   \n",
       "3     Chaka Khan              Half Moon   \n",
       "4      Passenger                  Holes   \n",
       "\n",
       "                                                text  \n",
       "0  May twelve angels guard you  \\r\\nWhile you sle...  \n",
       "1  [Hook]  \\r\\nBlaze it up and we'll be cruisin' ...  \n",
       "2  Yeah, yeah!  \\r\\nFool you know how we do it  \\...  \n",
       "3  Half Moon, Nighttime sky  \\r\\nSilver stone, He...  \n",
       "4  I know a man with nothing in his hands, nothin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c871aa7-5c01-4301-a6e0-cee3caa23e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"May twelve angels guard you  \\r\\nWhile you sleep  \\r\\nMaybe that's a waste of angels I don't know  \\r\\nI'd do anything to keep you safe  \\r\\nFrom the danger that surrounds us  \\r\\n  \\r\\nLittle by little  \\r\\nBit by bit  \\r\\nLittle bit by little bit  \\r\\nNow you got it that's it  \\r\\nWhat're you thinking  \\r\\nThings'll go sour?  \\r\\nCheck its temperature every hour  \\r\\nNervous when you own it  \\r\\nNervous when it's gone  \\r\\nWhat do you think has been going on  \\r\\nFor so long?  \\r\\n  \\r\\nYou are the air  \\r\\nInside my chest  \\r\\n  \\r\\nYou're the one  \\r\\nYou broke my heart  \\r\\nYou made me cry  \\r\\nYou're the one  \\r\\nYou broke my heart  \\r\\nYou made me cry  \\r\\nYou're the one  \\r\\nYou broke my heart  \\r\\nYou made me cry  \\r\\nYou're the one  \\r\\n  \\r\\nBut when I hear it from the other side  \\r\\nIt's a completely different song  \\r\\nI'm the one who made you cry  \\r\\nAnd I'm the one who's wrong  \\r\\nIn my dream you spoke to me  \\r\\nAnd you said  \\r\\n  \\r\\nYou're the one  \\r\\nYou broke my heart  \\r\\nYou made me cry  \\r\\nYou're the one  \\r\\nYou broke my heart  \\r\\nYou made me cry  \\r\\nYou're the one  \\r\\nYou broke my heart  \\r\\nYou made me cry  \\r\\nYou're the one  \\r\\n  \\r\\nNature gives us shapeless shapes  \\r\\nClouds and waves and flame  \\r\\nBut human expectation  \\r\\nIs that love remains the same  \\r\\nAnd when it doesn't  \\r\\nWe point our fingers  \\r\\nAnd blame blame blame  \\r\\n  \\r\\nYou're the one  \\r\\nYou broke my heart  \\r\\nYou made me cry  \\r\\nAnd I'm the one  \\r\\nI broke your heart  \\r\\nI made you cry  \\r\\nAnd you're the one  \\r\\nYou broke my heart  \\r\\nYou made me cry  \\r\\nWe're the ones\\r\\n\\r\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a3ec4-54a3-4616-83bc-c1948d45b280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c539db14-1b53-4da1-a5a0-cb1fd44a6501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5765, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e6fc07-6151-4bcf-982e-088f4e9073b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text cleaning\n",
    "df_sample['text'] = df_sample['text'].str.lower().replace(r'^\\w\\s',' ').replace(r'\\n',' ',regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5f3815-4f4b-45da-aaf7-3af20ce6be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703f83fe-a6d2-4fb4-9ffe-d16e7d4b6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999390d6-ca30-4095-9be0-8e94f66664ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(txt):\n",
    "    token = nltk.word_tokenize(txt)\n",
    "    a = [stemmer.stem(w) for w in token]\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf5b0e50-0fdb-4607-83a3-021ecfc9ef47",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\singh/nltk_data'\n    - 'c:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\nltk_data'\n    - 'c:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\singh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_sample[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtoken\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mtoken\u001b[39m\u001b[34m(txt)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtoken\u001b[39m(txt):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     token = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     a = [stemmer.stem(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m token]\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(a)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[39m, in \u001b[36mword_tokenize\u001b[39m\u001b[34m(text, language, preserve_line)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mword_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m, preserve_line=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     sentences = [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    144\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer.tokenize(sent)\n\u001b[32m    145\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\singh/nltk_data'\n    - 'c:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\nltk_data'\n    - 'c:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\singh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\singh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "df_sample['text'].apply(lambda x: token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "659b6e35-25b6-4324-ba2b-ab8f67b67e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8e32ed-1942-4f84-8384-dba04fa89209",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(analyzer='word',stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48df8727-ced5-4362-9386-67b653ce7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = tfid.fit_transform(df_sample['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b5a8cca-e372-4d02-b1d7-899489c7ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = cosine_similarity(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4356eac-3ec0-4570-859e-68c74019a2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.01142696, 0.02002571, ..., 0.00320822, 0.01441726,\n",
       "       0.01426004], shape=(5765,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5c45ba3-d093-4247-9e04-70f113f8dc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>Christina Aguilera</td>\n",
       "      <td>Bionic</td>\n",
       "      <td>this-this-this-this is the moment that i take ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5761</th>\n",
       "      <td>Horrible Histories</td>\n",
       "      <td>William Shakespeare Song</td>\n",
       "      <td>my name is shakespeare, william  \\r i owned a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5762</th>\n",
       "      <td>Iggy Pop</td>\n",
       "      <td>Strong Girl</td>\n",
       "      <td>i need a strong girl  \\r cause war's where i'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>Monarchy Of Roses</td>\n",
       "      <td>the crimson tide is flowing through your finge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>George Strait</td>\n",
       "      <td>I Look At You</td>\n",
       "      <td>sometimes i can't put up with bein' so put dow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     artist                      song  \\\n",
       "5760     Christina Aguilera                    Bionic   \n",
       "5761     Horrible Histories  William Shakespeare Song   \n",
       "5762               Iggy Pop               Strong Girl   \n",
       "5763  Red Hot Chili Peppers         Monarchy Of Roses   \n",
       "5764          George Strait             I Look At You   \n",
       "\n",
       "                                                   text  \n",
       "5760  this-this-this-this is the moment that i take ...  \n",
       "5761  my name is shakespeare, william  \\r i owned a ...  \n",
       "5762  i need a strong girl  \\r cause war's where i'm...  \n",
       "5763  the crimson tide is flowing through your finge...  \n",
       "5764  sometimes i can't put up with bein' so put dow...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53b7b23a-43ce-4ddc-8908-0e31d8bb263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1335)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['song'] == 'The Last Time'].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c2472-2fa8-4716-ab09-c8bd62872ab8",
   "metadata": {},
   "source": [
    "Recommender Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57d6793-173a-4534-ba16-800a5112ae4d",
   "metadata": {},
   "source": [
    "Recommender Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26d3030c-0c83-4b41-af74-1f2beae3e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(song_name):\n",
    "    idx = df[df['song'] == song_name].index[0]\n",
    "    distance = sorted(list(enumerate(similar[idx])),reverse = True,key = lambda x:x[1])\n",
    "    song = []\n",
    "    for s_id in distance[1:21]:\n",
    "        song.append(df.iloc[s_id[0]].song)\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58880852-6a53-412c-95cb-fb4190d430a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Muntik Na Kitang Minahal',\n",
       " 'Jo Jo Gunne',\n",
       " 'Dan, My Fling',\n",
       " 'Despise You',\n",
       " 'I Am',\n",
       " 'Iron John',\n",
       " 'Children Will Listen',\n",
       " 'Eleanor Young',\n",
       " 'Mouth 2 Mouth',\n",
       " \"It's All In The Game\",\n",
       " 'I Paralyze',\n",
       " 'I Never Thought',\n",
       " 'Reconsider (U Betta)',\n",
       " 'Making Plans',\n",
       " \"I'm Your Witch Doctor\",\n",
       " 'Bang-A-Boomerang',\n",
       " 'The Guns Of Brixton',\n",
       " 'Anna Lee, The Healer',\n",
       " 'After All',\n",
       " 'Atlantic City']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender(\"The Last Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a0bdbb4-8655-467f-9769-9768a22e31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09b8dc5f-9d20-46f2-bf2c-e905169e64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(similar, open(\"similarity\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89c528ed-8576-4272-a64c-644fc837ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df,open(\"df\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
